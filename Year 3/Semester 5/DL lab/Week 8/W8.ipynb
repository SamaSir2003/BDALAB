{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291dfda1-b6a2-460a-b41b-593b8bb1d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 01:48:15.429407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 01:48:16.327654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Embedding, Dropout, Input, Concatenate, TimeDistributed\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d70dc8e-be63-4506-ae36-415a10d29d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hin.txt','r') as f:\n",
    "  data = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncleaned_data_list = data.split('\\n')\n",
    "uncleaned_data_list.pop()\n",
    "len(uncleaned_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ca1019-21fc-41df-8bff-224f4a0c04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_word = []\n",
    "hindi_word = []\n",
    "cleaned_data_list = []\n",
    "\n",
    "for word in uncleaned_data_list:\n",
    "  split = word.split('\\t')\n",
    "  english_word.append(split[0])\n",
    "  hindi_word.append(split[1])\n",
    "\n",
    "language_data = pd.DataFrame(columns=['English','Hindi'])\n",
    "language_data['English'] = english_word\n",
    "language_data['Hindi'] = hindi_word\n",
    "language_data.to_csv('language_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English  Hindi\n",
       "0    Wow!   वाह!\n",
       "1   Duck!  झुको!\n",
       "2   Duck!  बतख़!\n",
       "3   Help!  बचाओ!\n",
       "4   Jump.  उछलो."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2979, 2979)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text = language_data['English'].values\n",
    "hindi_text = language_data['Hindi'].values\n",
    "len(english_text), len(hindi_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b6cb9d-f099-4d46-87b3-edeb4edc30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text_ = [x.lower() for x in english_text]\n",
    "hindi_text_ = [x.lower() for x in hindi_text]\n",
    "\n",
    "english_text_ = [re.sub(\"'\",'',x) for x in english_text_]\n",
    "hindi_text_ = [re.sub(\"'\",'',x) for x in hindi_text_]\n",
    "\n",
    "def remove_punc(text_list):\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  removed_punc_text = []\n",
    "  for sent in text_list:\n",
    "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
    "    removed_punc_text.append(' '.join(sentance))\n",
    "  return removed_punc_text\n",
    "\n",
    "english_text_ = remove_punc(english_text_)\n",
    "hindi_text_ = remove_punc(hindi_text_)\n",
    "\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "removed_digits_text = []\n",
    "for sent in english_text_:\n",
    "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
    "  removed_digits_text.append(' '.join(sentance))\n",
    "\n",
    "english_text_ = removed_digits_text\n",
    "hindi_text_ = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in hindi_text_]\n",
    "hindi_text_ = [re.sub(\"[\\u200d]\",\"\",x) for x in hindi_text_]\n",
    "\n",
    "english_text_ = [x.strip() for x in english_text_]\n",
    "hindi_text_ = [x.strip() for x in hindi_text_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start वाह end', 'wow')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_text_ = [\"start \" + x + \" end\" for x in hindi_text_]\n",
    "hindi_text_[0], english_text_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = english_text_\n",
    "Y = hindi_text_\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_length(data):\n",
    "  max_length_ = max([len(x.split(' ')) for x in data])\n",
    "  return max_length_\n",
    "\n",
    "max_length_english = max_length(X_train)\n",
    "max_length_hindi = max_length(y_train)\n",
    "max_length_english_test = max_length(X_test)\n",
    "max_length_hindi_test = max_length(y_test)\n",
    "max_length_hindi, max_length_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2273, 2892)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishTokenizer = Tokenizer()\n",
    "englishTokenizer.fit_on_texts(X_train)\n",
    "Eword2index = englishTokenizer.word_index\n",
    "vocab_size_source = len(Eword2index) + 1\n",
    "\n",
    "X_train = englishTokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
    "X_test = englishTokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen = max_length_english, padding='post')\n",
    "\n",
    "hindiTokenizer = Tokenizer()\n",
    "hindiTokenizer.fit_on_texts(y_train)\n",
    "Hword2index = hindiTokenizer.word_index\n",
    "vocab_size_target = len(Hword2index) + 1\n",
    "\n",
    "y_train = hindiTokenizer.texts_to_sequences(y_train)\n",
    "y_train = pad_sequences(y_train, maxlen=max_length_hindi, padding='post')\n",
    "y_test = hindiTokenizer.texts_to_sequences(y_test)\n",
    "y_test = pad_sequences(y_test, maxlen = max_length_hindi, padding='post')\n",
    "\n",
    "vocab_size_source, vocab_size_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2) Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "logger = tf.get_logger()\n",
    "\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(\n",
    "            name=\"W_a\",\n",
    "            shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.U_a = self.add_weight(\n",
    "            name=\"U_a\",\n",
    "            shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.V_a = self.add_weight(\n",
    "            name=\"V_a\",\n",
    "            shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super(AttentionLayer, self).build(\n",
    "            input_shape\n",
    "        )  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "\n",
    "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
    "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\"Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            logger.debug(\"Running energy computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(\n",
    "                    f\"States must be an iterable. Got {states} of type {type(states)}\"\n",
    "                )\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_full_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(\n",
    "                K.dot(inputs, self.U_a), 1\n",
    "            )  # <= batch_size, 1, latent_dim\n",
    "\n",
    "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "\n",
    "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\"Step function for computing ci using ei\"\"\"\n",
    "\n",
    "            logger.debug(\"Running attention vector computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(\n",
    "                    f\"States must be an iterable. Got {states} of type {type(states)}\"\n",
    "                )\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "\n",
    "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
    "\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        # we don't maintain states between steps when computing attention\n",
    "        # attention is stateless, so we're passing a fake state for RNN step function\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(\n",
    "            encoder_out_seq, axis=2\n",
    "        )  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"Outputs produced by the layer\"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1])),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 01:48:19.650609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.673920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.674002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.678141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.678233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.678292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.893528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.893622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.893633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-25 01:48:19.893691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:22:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 01:48:19.893721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4714 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:22:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 22)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 22, 500)              1136500   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 22, 500),            2002000   ['embedding[0][0]']           \n",
      "                              (None, 500),                                                        \n",
      "                              (None, 500)]                                                        \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 22, 500),            2002000   ['lstm[0][0]']                \n",
      "                              (None, 500),                                                        \n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 22)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 22, 500)              1136500   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 22, 500),            2002000   ['embedding[0][0]']           \n",
      "                              (None, 500),                                                        \n",
      "                              (None, 500)]                                                        \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 22, 500),            2002000   ['lstm[0][0]']                \n",
      "                              (None, 500),                                                        \n",
      "                              (None, 500)]                                                        \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 500)            1446000   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 22, 500),            2002000   ['lstm_1[0][0]']              \n",
      "                              (None, 500),                                                        \n",
      "                              (None, 500)]                                                        \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 500),          2002000   ['embedding_1[0][0]',         \n",
      "                              (None, 500),                           'lstm_2[0][1]',              \n",
      "                              (None, 500)]                           'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " attention_layer (Attention  ((None, None, 500),          500500    ['lstm_2[0][0]',              \n",
      " Layer)                       (None, None, 22))                      'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, None, 1000)           0         ['lstm_3[0][0]',              \n",
      "                                                                     'attention_layer[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, None, 2892)           2894892   ['concat_layer[0][0]']        \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13985892 (53.35 MB)\n",
      "Trainable params: 13985892 (53.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "latent_dim = 500\n",
    "\n",
    "encoder_inputs = Input(shape=(max_length_english,))\n",
    "enc_emb = Embedding(vocab_size_source, latent_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(vocab_size_target, latent_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "attn_layer = AttentionLayer()\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 01:48:29.316893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-25 01:48:29.876521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8c39850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-25 01:48:29.876592: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2023-10-25 01:48:29.882472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-25 01:48:30.121126: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-10-25 01:48:30.193297: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 14s 968ms/step - loss: 7.8910 - accuracy: 0.5359 - val_loss: 7.7582 - val_accuracy: 0.7235\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 4s 653ms/step - loss: 7.4134 - accuracy: 0.2069 - val_loss: 9.1788 - val_accuracy: 0.0023\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 4s 650ms/step - loss: 6.7848 - accuracy: 0.3991 - val_loss: 2.4809 - val_accuracy: 0.7235\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 4s 652ms/step - loss: 3.2842 - accuracy: 0.6987 - val_loss: 2.5978 - val_accuracy: 0.7235\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 4s 655ms/step - loss: 4.9442 - accuracy: 0.5385 - val_loss: 2.3609 - val_accuracy: 0.7235\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 4s 659ms/step - loss: 4.8069 - accuracy: 0.6425 - val_loss: 2.7582 - val_accuracy: 0.7235\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 4s 647ms/step - loss: 3.9417 - accuracy: 0.6914 - val_loss: 2.2017 - val_accuracy: 0.7235\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 4s 649ms/step - loss: 3.6930 - accuracy: 0.6736 - val_loss: 8.8441 - val_accuracy: 0.3548\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 4s 645ms/step - loss: 4.4320 - accuracy: 0.6226 - val_loss: 8.8885 - val_accuracy: 0.3545\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 4s 654ms/step - loss: 3.6945 - accuracy: 0.5901 - val_loss: 5.1188 - val_accuracy: 0.4769\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 4s 629ms/step - loss: 4.4007 - accuracy: 0.6088 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 4s 637ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 4s 634ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 4s 639ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 4s 641ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 4s 634ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 4s 631ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 4s 641ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 4s 637ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 4s 639ms/step - loss: nan - accuracy: 0.6988 - val_loss: nan - val_accuracy: 0.7235\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train, y_train[:, :-1]],\n",
    "    y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(\n",
    "        [X_test, y_test[:, :-1]],\n",
    "        y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:, 1:],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=500\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h, state_c = model.layers[6].output\n",
    "\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(22,latent_dim))\n",
    "\n",
    "decoder_inputs = model.layers[3].output\n",
    "\n",
    "dec_emb_layer = model.layers[5]\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = model.layers[7]\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "attn_layer = model.layers[8]\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "concate = model.layers[9]\n",
    "decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "decoder_dense = model.layers[10]\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eindex2word = englishTokenizer.index_word\n",
    "Hindex2word = hindiTokenizer.index_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    target_seq[0, 0] = Hword2index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        if sampled_token_index == 0:\n",
    "            break\n",
    "        else:\n",
    "            sampled_token = Hindex2word[sampled_token_index]\n",
    "            if sampled_token != 'end':\n",
    "                decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        if sampled_token == 'end' or len(decoded_sentence.split()) >= (26-1):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString = \"\"\n",
    "    for i in input_seq:\n",
    "        if (i != 0 and i != Hword2index[\"start\"]) and i != Hword2index[\"end\"]:\n",
    "            newString = newString + Hindex2word[i] + \" \"\n",
    "    return newString\n",
    "\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString = \"\"\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + Eindex2word[i] + \" \"\n",
    "    return newString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: hes already left \n",
      "Original summary: वह है। \n",
      "(22,)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: do you know how to drive a car \n",
      "Original summary: क्या तुमको गाड़ी चलाना आता है \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: almost all the leaves have \n",
      "Original summary: लगभग गिर चुकीं हैं। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: tom can be stubborn \n",
      "Original summary: टॉम बहुत हो सकता है। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: youre your shirt out \n",
      "Original summary: तुमने अपनी पहनी हुई है। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: he decided not to go to the party \n",
      "Original summary: उसने पार्टी में न जाने का फ़ैसला किया। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: answer me \n",
      "Original summary: मुझे जवाब दो। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: he went there instead of me \n",
      "Original summary: वह मेरे बजाय वहां गया। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: we celebrated his birthday \n",
      "Original summary: हमने उसका जन्मदिन मनाया। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n",
      "Review: i advise you to stop smoking \n",
      "Original summary: मैं तुम्हें सिगरेट पीना छोड़ देने की सलाह देना चाहता हूँ। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Review:\", seq2text(X_test[i]))\n",
    "    print(\"Original summary:\", seq2summary(y_test[i]))\n",
    "    print(X_test[i].shape)\n",
    "    print(\"Predicted summary:\", decode_sequence(X_test[i].reshape(1, 22)))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3) Pretrained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep/miniconda3/envs/dse/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"bert-base-cased\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the weights of TFBertForPreTraining were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n",
      "All the weights of TFBertForPreTraining were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/tasks/translation\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForPreTraining\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForPreTraining.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(list(language_data[\"English\"]), text_target=list(language_data[\"Hindi\"]), truncation=True, padding=True, max_length=200)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForPreTraining.\n",
      "\n",
      "All the weights of TFBertForPreTraining were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n",
      "All the weights of TFBertForPreTraining were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForPreTraining\n",
    "\n",
    "model = TFBertForPreTraining.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nTFBertForPreTraining requires the 🤗 Datasets library but it was not found in your environment. You can install it with:\n```\npip install datasets\n```\nIn a notebook or a colab, you can install it by executing a cell with\n```\n!pip install datasets\n```\nthen restarting your kernel.\n\nNote that if you have a local folder named `datasets` or a local python file named `datasets.py` in your current\nworking directory, python may try to import this instead of the 🤗 Datasets library. You should rename this folder or\nthat python file if that's the case. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/mnt/f/Programming/DSE/Year 3/Semester 5/DL lab/Week 8/W8.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bfedora/mnt/f/Programming/DSE/Year%203/Semester%205/DL%20lab/Week%208/W8.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tf_train_set \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mprepare_tf_dataset(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bfedora/mnt/f/Programming/DSE/Year%203/Semester%205/DL%20lab/Week%208/W8.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     train_encodings,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bfedora/mnt/f/Programming/DSE/Year%203/Semester%205/DL%20lab/Week%208/W8.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bfedora/mnt/f/Programming/DSE/Year%203/Semester%205/DL%20lab/Week%208/W8.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bfedora/mnt/f/Programming/DSE/Year%203/Semester%205/DL%20lab/Week%208/W8.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     collate_fn\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bfedora/mnt/f/Programming/DSE/Year%203/Semester%205/DL%20lab/Week%208/W8.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dse/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1438\u001b[0m, in \u001b[0;36mTFPreTrainedModel.prepare_tf_dataset\u001b[0;34m(self, dataset, batch_size, shuffle, tokenizer, collate_fn, collate_fn_args, drop_remainder, prefetch)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_tf_dataset\u001b[39m(\n\u001b[1;32m   1393\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1394\u001b[0m     dataset: \u001b[39m\"\u001b[39m\u001b[39mdatasets.Dataset\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# noqa:F821\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     prefetch: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1402\u001b[0m ):\n\u001b[1;32m   1403\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m \u001b[39m    Wraps a HuggingFace [`~datasets.Dataset`] as a `tf.data.Dataset` with collation and batching. This method is\u001b[39;00m\n\u001b[1;32m   1405\u001b[0m \u001b[39m    designed to create a \"ready-to-use\" dataset that can be passed directly to Keras methods like `fit()` without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[39m        `Dataset`: A `tf.data.Dataset` which is ready to pass to the Keras API.\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1438\u001b[0m     requires_backends(\u001b[39mself\u001b[39;49m, [\u001b[39m\"\u001b[39;49m\u001b[39mdatasets\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m   1439\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m collate_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dse/lib/python3.11/site-packages/transformers/utils/import_utils.py:1210\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1208\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[1;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m-> 1210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nTFBertForPreTraining requires the 🤗 Datasets library but it was not found in your environment. You can install it with:\n```\npip install datasets\n```\nIn a notebook or a colab, you can install it by executing a cell with\n```\n!pip install datasets\n```\nthen restarting your kernel.\n\nNote that if you have a local folder named `datasets` or a local python file named `datasets.py` in your current\nworking directory, python may try to import this instead of the 🤗 Datasets library. You should rename this folder or\nthat python file if that's the case. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    train_encodings,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
